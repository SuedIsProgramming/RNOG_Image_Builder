{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "97e9f8b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/condor_shared/users/ssued/mlvenv/lib/python3.10/site-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n",
      "  warnings.warn(\n",
      "/data/condor_shared/users/ssued/mlvenv/lib/python3.10/site-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "RNO_four_late_non_linear_merge           [128, 3]                  --\n",
       "├─Sequential: 1-1                        [128, 32, 24, 512, 4]     --\n",
       "│    └─BatchNorm3d: 2-1                  [128, 1, 24, 1024, 4]     2\n",
       "│    └─Conv3d: 2-2                       [128, 32, 24, 1024, 4]    320\n",
       "│    └─LeakyReLU: 2-3                    [128, 32, 24, 1024, 4]    --\n",
       "│    └─Conv3d: 2-4                       [128, 32, 24, 1024, 4]    9,248\n",
       "│    └─LeakyReLU: 2-5                    [128, 32, 24, 1024, 4]    --\n",
       "│    └─MaxPool3d: 2-6                    [128, 32, 24, 512, 4]     --\n",
       "│    └─Conv3d: 2-7                       [128, 32, 24, 512, 4]     9,248\n",
       "│    └─LeakyReLU: 2-8                    [128, 32, 24, 512, 4]     --\n",
       "├─Sequential: 1-2                        [128, 32, 24, 256, 4]     --\n",
       "│    └─AdaptiveMaxPool3d: 2-9            [128, 32, 24, 256, 4]     --\n",
       "├─Sequential: 1-3                        [128, 3]                  --\n",
       "│    └─Flatten: 2-10                     [128, 786432]             --\n",
       "│    └─Linear: 2-11                      [128, 256]                201,326,848\n",
       "│    └─LeakyReLU: 2-12                   [128, 256]                --\n",
       "│    └─Dropout: 2-13                     [128, 256]                --\n",
       "│    └─Linear: 2-14                      [128, 128]                32,896\n",
       "│    └─LeakyReLU: 2-15                   [128, 128]                --\n",
       "│    └─Dropout: 2-16                     [128, 128]                --\n",
       "│    └─Linear: 2-17                      [128, 3]                  387\n",
       "==========================================================================================\n",
       "Total params: 201,378,949\n",
       "Trainable params: 201,378,949\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (G): 204.35\n",
       "==========================================================================================\n",
       "Input size (MB): 50.33\n",
       "Forward/backward pass size (MB): 8154.12\n",
       "Params size (MB): 805.52\n",
       "Estimated Total Size (MB): 9009.97\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath(\"/data/condor_shared/users/ssued/RNOG_Image_Builder/machine_learning\"))\n",
    "from utils_dir import dataset, models, utils, ScaledTanh\n",
    "from torchinfo import summary\n",
    "\n",
    "model_test = models.RNO_four_late_non_linear_merge(1,32,3,temporal_res=256)\n",
    "\n",
    "summary(model_test, input_size=[128, 1, 24, 1024, 4]) # do a test pass through of an example input size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "51349130",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/condor_shared/users/ssued/mlvenv/lib/python3.10/site-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n",
      "  warnings.warn(\n",
      "/data/condor_shared/users/ssued/mlvenv/lib/python3.10/site-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.8.0+cu128\n",
      "True\n",
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import torch\n",
    "import torch.nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torch import nn\n",
    "sys.path.append(os.path.abspath(\"/data/condor_shared/users/ssued/machine_learning\"))\n",
    "from utils_dir import dataset, model, utils, ScaledTanh\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "print(torch.__version__)\n",
    "print(torch.cuda.is_available())\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "286f6bb0",
   "metadata": {},
   "source": [
    "# Model to try..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5964487",
   "metadata": {},
   "source": [
    "## Notes:\n",
    "\n",
    "Want to make kernels and pools effective. This means considering the shape of my data for convolving. Considering that my data is: (channels x timebins x stations) I would probably want to lean towards:\n",
    "\n",
    "* channel/station convolution: I want the model to understand the relative voltages between different adjacent channels effectively.\n",
    "* max_pool for timebins: Indeed there are a LOT of zeroes here, so maybe just having the relative position is enough rather than keeping 1000 zeroes in the time bin array.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "5c3903ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# V1.0.0 Starting point\n",
    "\n",
    "# Let there be light!\n",
    "class vertex_finder_100(nn.Module):\n",
    "\n",
    "    def __init__(self,input_shape: int, hidden_units: int, output_shape: int):\n",
    "        super().__init__()\n",
    "        KERNEL_HEIGHT = 2\n",
    "        KERNEL_WIDTH = 1024/32 # Total time length / 32\n",
    "        KERNEL_DEPTH = 1\n",
    "        KERNEL_SIZE = (KERNEL_HEIGHT,KERNEL_WIDTH,KERNEL_DEPTH)\n",
    "\n",
    "        self.conv_block_1=nn.Sequential(\n",
    "            nn.Conv3d(in_channels=input_shape,\n",
    "                      out_channels=hidden_units,\n",
    "                      kernel_size=KERNEL_SIZE,\n",
    "                      stride=1),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        self.conv_block_2=nn.Sequential(\n",
    "            nn.Conv3d(in_channels=hidden_units,\n",
    "                      out_channels=hidden_units,\n",
    "                      kernel_size=KERNEL_SIZE,\n",
    "                      stride=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool3d(kernel_size=(1,8,1))\n",
    "        )\n",
    "        self.final_conv=nn.Sequential(\n",
    "            nn.Conv3d(in_channels=hidden_units,\n",
    "                      out_channels=output_shape,\n",
    "                      kernel_size=KERNEL_SIZE,\n",
    "                      stride=1),\n",
    "            # nn.ReLU(), remove final relu that removes negative values\n",
    "        )\n",
    "        self.final_pool = nn.AdaptiveAvgPool3d((1,1,1))\n",
    "        # self.scaled_tanh = ScaledTanh(scale=3000) # Self-made function\n",
    "\n",
    "    def forward(self,x):\n",
    "        x = self.conv_block_1(x)\n",
    "        x = self.conv_block_2(x)\n",
    "        x = self.final_conv(x)\n",
    "        x = self.final_pool(x)\n",
    "        # x = self.scaled_tanh(x)\n",
    "        x = torch.squeeze(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "8c69a506",
   "metadata": {},
   "outputs": [],
   "source": [
    "# V1.1.0 Add batch norm + hierarchical learning (A.K.A, learn local changes in first layers -> global changes in last layers)\n",
    "\n",
    "# Let there be light!\n",
    "class vertex_finder_110(nn.Module):\n",
    "\n",
    "    def __init__(self, input_shape: int, hidden_units: int, output_shape: int):\n",
    "        super().__init__()\n",
    "\n",
    "        self.local_conv_block = nn.Sequential( # Local block, will mainly focus on \n",
    "            nn.Conv3d(in_channels=input_shape,\n",
    "                    out_channels=hidden_units,\n",
    "                    kernel_size=(2, 4, 1),\n",
    "                    padding=(0, 2, 0)),\n",
    "            nn.BatchNorm3d(hidden_units),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv3d(in_channels=hidden_units,\n",
    "                    out_channels=hidden_units,\n",
    "                    kernel_size=(2, 4, 1),\n",
    "                    padding=(0, 1, 0)),\n",
    "            nn.BatchNorm3d(hidden_units),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        self.mid_conv_block = nn.Sequential(\n",
    "            nn.Conv3d(in_channels=hidden_units,\n",
    "                      out_channels=hidden_units,\n",
    "                      kernel_size=(2,4,2)),\n",
    "            nn.BatchNorm3d(hidden_units),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool3d(kernel_size=(2,4,2))\n",
    "        )\n",
    "\n",
    "        self.global_conv_block = nn.Sequential(\n",
    "            nn.Conv3d(in_channels=hidden_units,\n",
    "                      out_channels=output_shape,\n",
    "                      kernel_size=(2,8,1)),\n",
    "            nn.BatchNorm3d(output_shape),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool3d(kernel_size=(1, 8, 1))\n",
    "        )\n",
    "        \n",
    "        self.final_pool = nn.AdaptiveAvgPool3d((1,1,1))\n",
    "        self.scaled_tanh = ScaledTanh(scale=3000) # Self-made function\n",
    "\n",
    "    def forward(self,x):\n",
    "        x = self.local_conv_block(x)\n",
    "        x = self.mid_conv_block(x)\n",
    "        x = self.global_conv_block(x)\n",
    "        x = self.final_pool(x)\n",
    "        x = self.scaled_tanh(x)\n",
    "        x = torch.squeeze(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "016c8b1e",
   "metadata": {},
   "source": [
    "# Visualize Data dimensions..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a512ae2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 1, 24, 1024, 4])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "album_path = '/data/i3store/users/ssued/albums/RNO_album_10_09_2025/album_RNO4.hdf5'\n",
    "\n",
    "album = dataset.AlbumDataset(album_path)\n",
    "test_data = DataLoader(album,32,False)\n",
    "\n",
    "first = next(iter(test_data))\n",
    "\n",
    "first[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "076f6506",
   "metadata": {},
   "source": [
    "# Use summary to see if model will even run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "536123f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.8.0+cu128\n",
      "cuda\n",
      "Train album size: 4 | Test album size: 4\n",
      "Number of train batches: 2 | Number of test batches: 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3])\n",
      "torch.Size([2, 3])\n",
      "torch.Size([2, 1, 24, 1024, 4])\n",
      "torch.Size([2, 3])\n",
      "torch.Size([2, 3])\n",
      "torch.Size([2, 1, 24, 1024, 4])\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "import logging\n",
    "import torch\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Add utils directory to path\n",
    "sys.path.append('/data/condor_shared/users/ssued/machine_learning')\n",
    "\n",
    "# Import all functions from utils_dir (handled by __init__.py)\n",
    "from utils_dir import *\n",
    "\n",
    "# PARAMS =============================================================\n",
    "# Setup Batch size\n",
    "BATCH_SIZE = 2\n",
    "# Setup number of epochs to train\n",
    "NUM_EPOCHS = 1000\n",
    "# Use checkpoint if needed\n",
    "# checkpoint_name = 'checkpoint_e500.pth'\n",
    "# ====================================================================\n",
    "\n",
    "# Print out versions and device to make sure everything is working\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(torch.__version__)\n",
    "print(device)\n",
    "\n",
    "# Paths to album:\n",
    "album_path = '/data/i3store/users/ssued/albums/RNO_benchmark.hdf5'\n",
    "# train_album_path = '/i3store/users/ssued/albums/album_train.hdf5'\n",
    "# test_album_path = '/i3store/users/ssued/albums/album_test.hdf5'\n",
    "\n",
    "# Load Datasets\n",
    "# album = AlbumDataset(album_path, transform=None, target_transform=None)\n",
    "train_album = AlbumDataset(album_path, transform=None, target_transform=None)\n",
    "test_album = AlbumDataset(album_path, transform=None, target_transform=None)\n",
    "\n",
    "print(f'Train album size: {train_album.num_images} | Test album size: {test_album.num_images}')\n",
    "\n",
    "# Load DataLoaders\n",
    "train_data_loader = DataLoader(dataset = train_album,\n",
    "                               batch_size = BATCH_SIZE,\n",
    "                               shuffle = True,\n",
    "                               num_workers = 3)\n",
    "test_data_loader = DataLoader(dataset = test_album,\n",
    "                              batch_size = BATCH_SIZE,\n",
    "                              shuffle = False,\n",
    "                              num_workers = 3)\n",
    "\n",
    "print(f'Number of train batches: {len(train_data_loader)} | Number of test batches: {len(test_data_loader)}')\n",
    "\n",
    "# Initialize model\n",
    "model = RNO_four_1_0_0(input_shape=1,\n",
    "                          hidden_units=10, \n",
    "                          output_shape=3,\n",
    "                          num_epochs=NUM_EPOCHS,\n",
    "                          batch_size=BATCH_SIZE,\n",
    "                          num_train_batches=len(train_data_loader)\n",
    "                         )\n",
    "\n",
    "\n",
    "for X, y in train_data_loader:\n",
    "    y_pred = model(X)\n",
    "    print(y_pred.shape)\n",
    "    print(y.shape)\n",
    "    print(X.shape)\n",
    "    loss_fn = torch.nn.HuberLoss(delta=50)\n",
    "    loss = loss_fn(y_pred, y)\n",
    "    #print(loss)\n",
    "\n",
    "# # Setup optimizer\n",
    "# optimizer = torch.optim.Adam(params=model.parameters())\n",
    "# optimizer_name = optimizer.__class__.__name__\n",
    "# # Setup loss function\n",
    "# #loss_fn = torch.nn.HuberLoss(delta=50)\n",
    "# loss_fn = torch.nn.MSELoss()\n",
    "# loss_fn_name = loss_fn.__class__.__name__\n",
    "\n",
    "# experiment_name = (f'exp_e{NUM_EPOCHS}' +\n",
    "#                   f'_bn{BATCH_SIZE}' +\n",
    "#                   f'_tr{len(train_data_loader)}' +\n",
    "#                   f'_te{len(test_data_loader)}' +\n",
    "#                   f'_lfn-{loss_fn_name}' +\n",
    "#                   f'_opt-{optimizer_name}' +\n",
    "#                   f'_del{50}')\n",
    "\n",
    "# # Create experiments directory if it doesn't exist\n",
    "# os.makedirs('experiments', exist_ok=True)\n",
    "\n",
    "# # Create specific experiment directory if it doesn't exist\n",
    "# experiment_path = os.path.join('experiments', experiment_name)\n",
    "# os.makedirs(experiment_path, exist_ok=True)\n",
    "\n",
    "# # Setup logging\n",
    "# logger = logging.getLogger('experiment_log') # Setup logging\n",
    "# logging.basicConfig(filename=f'{experiment_path}/experiment.log',\n",
    "#                     filemode='w',\n",
    "#                     level=logging.DEBUG,\n",
    "#                     format='[%(levelname)s: %(asctime)s] %(message)s',\n",
    "#                     datefmt='%m/%d/%Y %I:%M:%S %p')\n",
    "\n",
    "# logger.info(f\"Starting experiment: {experiment_name}\")\n",
    "# logger.info(f\"Device: {device}\")\n",
    "# logger.info(f\"PyTorch version: {torch.__version__}\")\n",
    "# logger.info(f\"Model: {type(model).__name__}\")\n",
    "# logger.info(f\"Optimizer: {optimizer_name}\")\n",
    "# logger.info(f\"Loss function: {loss_fn_name}\")\n",
    "\n",
    "# train_test(model = model, \n",
    "#            train_dataloader = train_data_loader, \n",
    "#            test_dataloader = test_data_loader, \n",
    "#            optimizer = optimizer,\n",
    "#            scheduler = None,\n",
    "#            loss_fn = loss_fn,\n",
    "#            device = device,\n",
    "#            experiment_name = experiment_name,\n",
    "#            epochs = NUM_EPOCHS,\n",
    "#            checkpoint_freq = 100,\n",
    "#            checkpoint_name = None,\n",
    "#            loss_file = 'losses.txt',\n",
    "#            logger = logger)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlvenv (3.10.12)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
